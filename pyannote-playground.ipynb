{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T07:15:09.765959Z","iopub.status.busy":"2024-04-10T07:15:09.765270Z","iopub.status.idle":"2024-04-10T07:15:38.562286Z","shell.execute_reply":"2024-04-10T07:15:38.561140Z","shell.execute_reply.started":"2024-04-10T07:15:09.765928Z"},"trusted":true},"outputs":[],"source":["!pip install pyannote.audio"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T07:15:38.564827Z","iopub.status.busy":"2024-04-10T07:15:38.564456Z","iopub.status.idle":"2024-04-10T07:15:52.102274Z","shell.execute_reply":"2024-04-10T07:15:52.101233Z","shell.execute_reply.started":"2024-04-10T07:15:38.564792Z"},"trusted":true},"outputs":[],"source":["!pip install pydub"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from pyannote.audio import Pipeline\n","import torch\n","import time\n","start = time.time()\n","pipeline = Pipeline.from_pretrained(\n","    \"pyannote/speaker-diarization-3.1\",\n","    use_auth_token=\"\"\n",")\n","# Move the pipeline to GPU if available\n","if torch.cuda.is_available():\n","    pipeline = pipeline.to(torch.device(\"cuda\"))\n","\n","    # apply pretrained pipeline\n","    diarization = pipeline(\"\")\n","\n","    # print the result\n","    for turn, _, speaker in diarization.itertracks(yield_label=True):\n","        print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n","    end = time.time()\n","    print(start-end)\n","else:\n","    print(\"Cannot do!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:11.062768Z","iopub.status.busy":"2024-04-08T12:01:11.061939Z","iopub.status.idle":"2024-04-08T12:09:26.786978Z","shell.execute_reply":"2024-04-08T12:09:26.786006Z","shell.execute_reply.started":"2024-04-08T12:01:11.062729Z"},"trusted":true},"outputs":[],"source":["from pyannote.audio import Pipeline\n","import torch\n","import time\n","import os\n","from pydub import AudioSegment\n","\n","# Function to split the audio into smaller chunks\n","def split_audio(input_audio, chunk_duration):\n","    chunk_length = chunk_duration * 1000  # Convert chunk duration from seconds to milliseconds\n","    chunks = []\n","    start = 0\n","    end = chunk_length\n","    while end <= len(input_audio):\n","        chunks.append(input_audio[start:end])\n","        start = end\n","        end += chunk_length\n","    # Add the last chunk (which may be shorter than chunk_length)\n","    if start < len(input_audio):\n","        chunks.append(input_audio[start:])\n","    return chunks\n","\n","start_time = time.time()\n","\n","pipeline = Pipeline.from_pretrained(\n","    \"pyannote/speaker-diarization-3.1\",\n","    use_auth_token=\"\"\n",")\n","\n","# Move the pipeline to GPU if available\n","if torch.cuda.is_available():\n","    pipeline = pipeline.to(torch.device(\"cuda\"))\n","\n","# Load the hour-long audio file\n","input_audio = AudioSegment.from_wav(\"\")\n","\n","# Define the output directory for audio chunks\n","output_dir = \"/kaggle/working/audio_chunks/\"\n","\n","# Create the output directory if it does not exist\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Define the duration of each chunk in seconds\n","chunk_duration = 300  # 5 minutes\n","\n","# Split the audio into smaller chunks\n","audio_chunks = split_audio(input_audio, chunk_duration)\n","\n","# Process each chunk\n","for i, chunk in enumerate(audio_chunks):\n","    chunk_output_path = os.path.join(output_dir, f\"chunk_{i+1}.wav\")\n","    chunk.export(chunk_output_path, format=\"wav\")  # Export the chunk to a WAV file\n","    print(f\"Processing chunk {i+1}/{len(audio_chunks)}...\")\n","    \n","    # Apply pretrained pipeline\n","    diarization = pipeline(chunk_output_path)\n","\n","    # Print the result\n","    for turn, _, speaker in diarization.itertracks(yield_label=True):\n","        print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n","\n","# Calculate and print the execution time\n","end_time = time.time()\n","print(\"Total execution time:\", end_time - start_time, \"seconds\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T07:17:34.280823Z","iopub.status.busy":"2024-04-10T07:17:34.280060Z","iopub.status.idle":"2024-04-10T07:18:37.690930Z","shell.execute_reply":"2024-04-10T07:18:37.689492Z","shell.execute_reply.started":"2024-04-10T07:17:34.280791Z"},"trusted":true},"outputs":[],"source":["from pyannote.audio import Pipeline\n","import torch\n","import time\n","import os\n","from pydub import AudioSegment\n","\n","# Function to split audio into smaller chunks\n","def split_audio(input_audio, chunk_duration):\n","    chunk_length = chunk_duration * 1000  # Convert chunk duration from seconds to milliseconds\n","    chunks = []\n","    start = 0\n","    end = chunk_length\n","    while end <= len(input_audio):\n","        chunks.append(input_audio[start:end])\n","        start = end\n","        end += chunk_length\n","    if start < len(input_audio):\n","        chunks.append(input_audio[start:])\n","    return chunks\n","\n","# Function to perform diarization on audio chunks\n","def diarize_audio_chunks(audio_chunks):\n","    pipeline = Pipeline.from_pretrained(\n","        \"pyannote/speaker-diarization-3.1\",\n","        use_auth_token=\"\"\n","    )\n","\n","    if torch.cuda.is_available():\n","        pipeline = pipeline.to(torch.device(\"cuda\"))\n","\n","    for i, chunk in enumerate(audio_chunks):\n","        chunk_file_path = f\"chunk_{i+1}.wav\"\n","        chunk.export(chunk_file_path, format=\"wav\")\n","        print(f\"Processing chunk {i + 1}/{len(audio_chunks)}...\")\n","        diarization = pipeline(chunk_file_path)\n","        for turn, _, speaker in diarization.itertracks(yield_label=True):\n","            print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n","        os.remove(chunk_file_path)  # Remove temporary file after processing\n","\n","# Read the WAV file\n","audio_file_path = \"\"\n","audio_file = AudioSegment.from_wav(audio_file_path)\n","\n","# Define chunk duration in seconds\n","chunk_duration = 60  # 1 minute\n","\n","# Split the audio into smaller chunks\n","audio_chunks = split_audio(audio_file, chunk_duration)\n","\n","# Perform diarization on audio chunks\n","diarize_audio_chunks(audio_chunks)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4727316,"sourceId":8022230,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
